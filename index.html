<!DOCTYPE html>
<html lang="vi">
<head>
<meta charset="UTF-8">
<title>Camera AI PhÃ¡t Hiá»‡n Váº­t Thá»ƒ + Zoom</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<style>
body {
    margin: 0;
    background: black;
    overflow: hidden;
    font-family: Arial;
}

#container {
    position: relative;
    width: 100vw;
    height: 100vh;
    overflow: hidden;
}

video, canvas {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    width: 100%;
    height: 100%;
    object-fit: cover;
    transition: transform 0.15s ease;
}

.controls {
    position: fixed;
    bottom: 15px;
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 12px;
    z-index: 10;
}

button {
    background: rgba(0,0,0,0.7);
    color: #0f0;
    border: 1px solid #0f0;
    border-radius: 30px;
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
}

#status {
    position: fixed;
    top: 10px;
    left: 10px;
    color: #0f0;
    background: rgba(0,0,0,0.6);
    padding: 8px 12px;
    border-radius: 8px;
    font-size: 14px;
    z-index: 10;
}
</style>
</head>

<body>

<div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
</div>

<div id="status">ğŸ“· Äang khá»Ÿi Ä‘á»™ng camera...</div>

<div class="controls">
    <button onclick="switchCamera()">ğŸ” Äá»•i camera</button>
    <button onclick="takePhoto()">ğŸ“¸ Chá»¥p áº£nh</button>
    <button onclick="zoomIn()">ğŸ” + Zoom</button>
    <button onclick="zoomOut()">ğŸ” - Zoom</button>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let status = document.getElementById("status");

let currentFacing = "environment"; // "user" hoáº·c "environment"
let stream = null;
let model = null;

// Zoom variables
let zoomLevel = 1;
const MIN_ZOOM = 1;
const MAX_ZOOM = 4;
const ZOOM_STEP = 0.3;

async function startCamera() {
    if (stream) {
        stream.getTracks().forEach(t => t.stop());
    }

    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: currentFacing },
            audio: false
        });
        video.srcObject = stream;
        status.innerText = "ğŸ“¹ Camera Ä‘Ã£ báº­t";
    } catch (err) {
        status.innerText = "âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera: " + err.message;
    }
}

function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    startCamera();
}

function takePhoto() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const a = document.createElement("a");
    a.download = "ai-photo-zoom.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
}

// Zoom functions
function applyZoom() {
    const scale = `scale(${zoomLevel})`;
    video.style.transform = `translate(-50%, -50%) ${scale}`;
    canvas.style.transform = `translate(-50%, -50%) ${scale}`;
}

function zoomIn() {
    zoomLevel = Math.min(zoomLevel + ZOOM_STEP, MAX_ZOOM);
    applyZoom();
    status.innerText = `ğŸ” Zoom: ${zoomLevel.toFixed(1)}x`;
}

function zoomOut() {
    zoomLevel = Math.max(zoomLevel - ZOOM_STEP, MIN_ZOOM);
    applyZoom();
    status.innerText = `ğŸ” Zoom: ${zoomLevel.toFixed(1)}x`;
}

async function loadAI() {
    status.innerText = "ğŸ¤– Äang táº£i mÃ´ hÃ¬nh AI (coco-ssd)...";
    try {
        model = await cocoSsd.load(); // CÃ³ thá»ƒ truyá»n { base: 'lite_mobilenet_v2' } náº¿u muá»‘n nháº¹ hÆ¡n
        status.innerText = "âœ… AI sáºµn sÃ ng - PhÃ¡t hiá»‡n má»i váº­t thá»ƒ";
        detect();
    } catch (err) {
        status.innerText = "âŒ Lá»—i táº£i AI: " + err.message;
    }
}

async function detect() {
    if (video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrame(detect);
        return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const predictions = await model.detect(video);

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // Váº½ bounding box cho má»i váº­t thá»ƒ (Ä‘áº·c biá»‡t ná»•i báº­t "person")
    predictions.forEach(p => {
        const [x, y, w, h] = p.bbox;
        const isPerson = p.class === "person";

        ctx.strokeStyle = isPerson ? "#ff3366" : "#00ff00"; // Äá» há»“ng cho ngÆ°á»i, xanh cho váº­t khÃ¡c
        ctx.lineWidth = isPerson ? 4 : 2;
        ctx.strokeRect(x, y, w, h);

        ctx.fillStyle = isPerson ? "#ff3366" : "#00ff00";
        ctx.font = isPerson ? "18px Arial" : "14px Arial";
        ctx.fillText(
            `${p.class} (${Math.round(p.score * 100)}%)`,
            x,
            y > 25 ? y - 8 : y + 18
        );
    });

    status.innerText = `ğŸ” PhÃ¡t hiá»‡n ${predictions.length} váº­t thá»ƒ (person: ${predictions.filter(p => p.class === "person").length})`;
    
    requestAnimationFrame(detect);
}

(async () => {
    await startCamera();
    await loadAI();
    applyZoom(); // Ãp dá»¥ng zoom ban Ä‘áº§u = 1
})();
</script>

</body>
</html>
