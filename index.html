<!DOCTYPE html>
<html lang="vi">
<head>
<meta charset="UTF-8">
<title>Camera AI Ph√°t Hi·ªán V·∫≠t Th·ªÉ + Zoom 10x + R√µ N√©t</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<style>
body {
    margin: 0;
    background: black;
    overflow: hidden;
    font-family: Arial;
}

#container {
    position: relative;
    width: 100vw;
    height: 100vh;
    overflow: hidden;
}

video, canvas {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    width: 100%;
    height: 100%;
    object-fit: cover;
    transition: transform 0.3s ease;
    image-rendering: crisp-edges; /* Gi√∫p n√©t h∆°n khi zoom */
}

.controls {
    position: fixed;
    bottom: 80px;
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 12px;
    z-index: 10;
}

.zoom-controls {
    position: fixed;
    bottom: 120px;
    left: 50%;
    transform: translateX(-50%);
    width: 80%;
    max-width: 300px;
    z-index: 10;
    text-align: center;
    color: #0f0;
}

.zoom-controls label {
    display: block;
    margin-bottom: 5px;
    font-size: 14px;
}

.zoom-slider {
    width: 100%;
    -webkit-appearance: none;
    height: 8px;
    background: rgba(0,255,0,0.3);
    border-radius: 5px;
    outline: none;
}

.zoom-slider::-webkit-slider-thumb {
    -webkit-appearance: none;
    width: 20px;
    height: 20px;
    background: #0f0;
    border-radius: 50%;
    cursor: pointer;
    border: 2px solid #000;
}

button {
    background: rgba(0,0,0,0.7);
    color: #0f0;
    border: 1px solid #0f0;
    border-radius: 30px;
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
}

#status {
    position: fixed;
    top: 10px;
    left: 10px;
    color: #0f0;
    background: rgba(0,0,0,0.6);
    padding: 8px 12px;
    border-radius: 8px;
    font-size: 14px;
    z-index: 10;
}
</style>
</head>

<body>

<div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
</div>

<div id="status">üì∑ ƒêang kh·ªüi ƒë·ªông camera...</div>

<div class="controls">
    <button onclick="switchCamera()">üîÅ ƒê·ªïi camera</button>
    <button onclick="takePhoto()">üì∏ Ch·ª•p ·∫£nh</button>
    <button onclick="zoomIn()">üîç +</button>
    <button onclick="zoomOut()">üîç -</button>
</div>

<div class="zoom-controls">
    <label>Zoom: <span id="zoomValue">1.0x</span></label>
    <input type="range" id="zoomSlider" class="zoom-slider" min="0.5" max="10" step="0.1" value="1" oninput="updateZoom(this.value)">
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let status = document.getElementById("status");
let zoomValueDisplay = document.getElementById("zoomValue");
let zoomSlider = document.getElementById("zoomSlider");

let currentFacing = "environment";
let stream = null;
let model = null;

let zoomLevel = 1;
const MIN_ZOOM = 0.5;
const MAX_ZOOM = 10;
const ZOOM_STEP = 0.5;

let frameCount = 0;
const detectInterval = 3;

// Sharpen kernel (nh·∫π, kh√¥ng qu√° m·∫°nh ƒë·ªÉ tr√°nh noise)
const sharpenKernel = [
    0, -1, 0,
    -1, 5, -1,
    0, -1, 0
];

async function startCamera() {
    if (stream) stream.getTracks().forEach(t => t.stop());

    try {
        // Constraints cho r√µ n√©t cao: ∆∞u ti√™n high-res, rear camera
        const constraints = {
            video: {
                facingMode: { ideal: currentFacing },
                width: { ideal: 1920, min: 1280 },
                height: { ideal: 1080, min: 720 },
                frameRate: { ideal: 30 },
                resizeMode: "crop-and-scale" // Gi·ªØ ch·∫•t l∆∞·ª£ng cao khi scale
            },
            audio: false
        };
        stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        status.innerText = "üìπ Camera ƒë√£ b·∫≠t - Ch·∫•t l∆∞·ª£ng cao";
    } catch (err) {
        status.innerText = "‚ùå L·ªói camera: " + err.message + " (th·ª≠ gi·∫£m res n·∫øu l·ªói)";
        // Fallback low res n·∫øu high fail
        const fallback = { video: { facingMode: currentFacing } };
        stream = await navigator.mediaDevices.getUserMedia(fallback);
        video.srcObject = stream;
    }
}

function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    startCamera();
}

function takePhoto() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    // √Åp sharpen khi ch·ª•p ƒë·ªÉ ·∫£nh n√©t h∆°n
    applySharpen();
    const a = document.createElement("a");
    a.download = "ai-photo-net.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
}

function applyZoom() {
    const scale = `scale(${zoomLevel})`;
    video.style.transform = `translate(-50%, -50%) ${scale}`;
    canvas.style.transform = `translate(-50%, -50%) ${scale}`;
    zoomValueDisplay.innerText = zoomLevel.toFixed(1) + 'x';
    zoomSlider.value = zoomLevel;
}

function zoomIn() {
    zoomLevel = Math.min(zoomLevel + ZOOM_STEP, MAX_ZOOM);
    applyZoom();
}

function zoomOut() {
    zoomLevel = Math.max(zoomLevel - ZOOM_STEP, MIN_ZOOM);
    applyZoom();
}

function updateZoom(value) {
    zoomLevel = parseFloat(value);
    applyZoom();
}

function updateStatus(predictions = []) {
    const personCount = predictions.filter(p => p.class === "person" && p.score > 0.5).length;
    status.innerText = `üîç Ph√°t hi·ªán ${predictions.length} v·∫≠t th·ªÉ (person: ${personCount}) | Zoom: ${zoomLevel.toFixed(1)}x | Res: ${video.videoWidth}x${video.videoHeight}`;
}

function applySharpen() {
    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
    const data = imageData.data;
    const tempData = new Uint8ClampedArray(data);

    for (let y = 1; y < canvas.height - 1; y++) {
        for (let x = 1; x < canvas.width - 1; x++) {
            const i = (y * canvas.width + x) * 4;
            let r = 0, g = 0, b = 0;

            for (let ky = -1; ky <= 1; ky++) {
                for (let kx = -1; kx <= 1; kx++) {
                    const idx = ((y + ky) * canvas.width + (x + kx)) * 4;
                    const weight = sharpenKernel[(ky + 1) * 3 + (kx + 1)];
                    r += tempData[idx] * weight;
                    g += tempData[idx + 1] * weight;
                    b += tempData[idx + 2] * weight;
                }
            }

            data[i] = Math.min(255, Math.max(0, r));
            data[i + 1] = Math.min(255, Math.max(0, g));
            data[i + 2] = Math.min(255, Math.max(0, b));
            data[i + 3] = 255;
        }
    }
    ctx.putImageData(imageData, 0, 0);
}

async function loadAI() {
    status.innerText = "ü§ñ ƒêang t·∫£i AI...";
    try {
        model = await cocoSsd.load({ base: 'lite_mobilenet_v2' });
        status.innerText = "‚úÖ AI s·∫µn s√†ng";
        detect();
    } catch (err) {
        status.innerText = "‚ùå L·ªói AI: " + err.message;
    }
}

async function detect() {
    if (video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrame(detect);
        return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // √Åp sharpen nh·∫π l√™n frame ƒë·ªÉ r√µ n√©t h∆°n (m·ªói frame)
    applySharpen();

    frameCount++;
    if (frameCount % detectInterval === 0) {
        const predictions = await model.detect(video);
        const filteredPreds = predictions.filter(p => p.score > 0.5);

        // V·∫Ω bounding box sau sharpen
        filteredPreds.forEach(p => {
            const [x, y, w, h] = p.bbox;
            const isPerson = p.class === "person";

            ctx.strokeStyle = isPerson ? "#ff3366" : "#00ff00";
            ctx.lineWidth = isPerson ? 4 : 2;
            ctx.strokeRect(x, y, w, h);

            ctx.fillStyle = isPerson ? "#ff3366" : "#00ff00";
            ctx.font = isPerson ? "18px Arial" : "14px Arial";
            ctx.fillText(
                `${p.class} (${Math.round(p.score * 100)}%)`,
                x,
                y > 25 ? y - 8 : y + 18
            );
        });

        updateStatus(filteredPreds);
    } else {
        updateStatus();
    }

    requestAnimationFrame(detect);
}

(async () => {
    await startCamera();
    await loadAI();
    applyZoom();
})();
</script>

</body>
</html>
