<!DOCTYPE html>
<html lang="vi">
<head>
<meta charset="UTF-8">
<title>Camera AI PhÃ¡t Hiá»‡n Váº­t Thá»ƒ</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<style>
body {
    margin: 0;
    background: black;
    overflow: hidden;
    font-family: Arial;
}

video, canvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100vw;
    height: 100vh;
    object-fit: cover;
}

.controls {
    position: fixed;
    bottom: 15px;
    width: 100%;
    display: flex;
    justify-content: center;
    gap: 10px;
    z-index: 10;
}

button {
    background: rgba(0,0,0,0.7);
    color: #0f0;
    border: 1px solid #0f0;
    border-radius: 30px;
    padding: 10px 14px;
}

#status {
    position: fixed;
    top: 10px;
    left: 10px;
    color: #0f0;
    background: rgba(0,0,0,0.6);
    padding: 6px 10px;
    border-radius: 6px;
    font-size: 13px;
    z-index: 10;
}
</style>
</head>

<body>

<video id="video" autoplay playsinline></video>
<canvas id="canvas"></canvas>

<div id="status">ğŸ“· Äang khá»Ÿi Ä‘á»™ng camera...</div>

<div class="controls">
    <button onclick="switchCamera()">ğŸ” Camera</button>
    <button onclick="takePhoto()">ğŸ“¸ Chá»¥p</button>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let status = document.getElementById("status");

let currentFacing = "environment";
let stream = null;
let model = null;

async function startCamera() {
    if (stream) stream.getTracks().forEach(t => t.stop());

    stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: currentFacing },
        audio: false
    });

    video.srcObject = stream;
}

function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    startCamera();
}

function takePhoto() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const a = document.createElement("a");
    a.download = "ai-photo.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
}

async function loadAI() {
    status.innerText = "ğŸ¤– Äang táº£i AI...";
    model = await cocoSsd.load();
    status.innerText = "âœ… AI sáºµn sÃ ng";
    detect();
}

async function detect() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const predictions = await model.detect(video);

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    predictions.forEach(p => {
        const [x, y, w, h] = p.bbox;
        ctx.strokeStyle = "#00ff00";
        ctx.lineWidth = 2;
        ctx.strokeRect(x, y, w, h);

        ctx.fillStyle = "#00ff00";
        ctx.font = "14px Arial";
        ctx.fillText(
            `${p.class} (${Math.round(p.score * 100)}%)`,
            x,
            y > 20 ? y - 5 : y + 15
        );
    });

    status.innerText = `ğŸ” PhÃ¡t hiá»‡n ${predictions.length} váº­t thá»ƒ`;
    requestAnimationFrame(detect);
}

(async () => {
    await startCamera();
    await loadAI();
})();
</script>

</body>
</html>
