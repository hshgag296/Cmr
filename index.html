<!DOCTYPE html>
<html lang="vi">
<head>
<meta charset="UTF-8">
<title>Camera AI PhÃ¡t Hiá»‡n Váº­t Thá»ƒ + Zoom 10x + Slider Giá»¯a</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>

<style>
body {
    margin: 0;
    background: black;
    overflow: hidden;
    font-family: Arial;
}

#container {
    position: relative;
    width: 100vw;
    height: 100vh;
    overflow: hidden;
}

video, canvas {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    width: 100%;
    height: 100%;
    object-fit: cover;
    transition: transform 0.3s ease;
}

.controls {
    position: fixed;
    bottom: 80px; /* Äá»ƒ chá»«a chá»— cho slider zoom á»Ÿ giá»¯a */
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 12px;
    z-index: 10;
}

.zoom-controls {
    position: fixed;
    bottom: 120px; /* Äáº·t slider zoom á»Ÿ giá»¯a dÆ°á»›i, giá»‘ng app camera */
    left: 50%;
    transform: translateX(-50%);
    width: 80%;
    max-width: 300px;
    z-index: 10;
    text-align: center;
    color: #0f0;
}

.zoom-controls label {
    display: block;
    margin-bottom: 5px;
    font-size: 14px;
}

.zoom-slider {
    width: 100%;
    -webkit-appearance: none;
    height: 8px;
    background: rgba(0,255,0,0.3);
    border-radius: 5px;
    outline: none;
}

.zoom-slider::-webkit-slider-thumb {
    -webkit-appearance: none;
    width: 20px;
    height: 20px;
    background: #0f0;
    border-radius: 50%;
    cursor: pointer;
    border: 2px solid #000;
}

button {
    background: rgba(0,0,0,0.7);
    color: #0f0;
    border: 1px solid #0f0;
    border-radius: 30px;
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
}

#status {
    position: fixed;
    top: 10px;
    left: 10px;
    color: #0f0;
    background: rgba(0,0,0,0.6);
    padding: 8px 12px;
    border-radius: 8px;
    font-size: 14px;
    z-index: 10;
}
</style>
</head>

<body>

<div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
</div>

<div id="status">ğŸ“· Äang khá»Ÿi Ä‘á»™ng camera...</div>

<div class="controls">
    <button onclick="switchCamera()">ğŸ” Äá»•i camera</button>
    <button onclick="takePhoto()">ğŸ“¸ Chá»¥p áº£nh</button>
    <button onclick="zoomIn()">ğŸ” +</button>
    <button onclick="zoomOut()">ğŸ” -</button>
</div>

<!-- Slider zoom á»Ÿ giá»¯a dÆ°á»›i -->
<div class="zoom-controls">
    <label>Zoom: <span id="zoomValue">1.0x</span></label>
    <input type="range" id="zoomSlider" class="zoom-slider" min="0.5" max="10" step="0.1" value="1" oninput="updateZoom(this.value)">
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let status = document.getElementById("status");
let zoomValueDisplay = document.getElementById("zoomValue");
let zoomSlider = document.getElementById("zoomSlider");

let currentFacing = "environment";
let stream = null;
let model = null;

// Zoom variables
let zoomLevel = 1;
const MIN_ZOOM = 0.5;
const MAX_ZOOM = 10;
const ZOOM_STEP = 0.5;

let frameCount = 0;
const detectInterval = 3;

async function startCamera() {
    if (stream) stream.getTracks().forEach(t => t.stop());

    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: currentFacing },
            audio: false
        });
        video.srcObject = stream;
        status.innerText = "ğŸ“¹ Camera Ä‘Ã£ báº­t";
    } catch (err) {
        status.innerText = "âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera: " + err.message;
    }
}

function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    startCamera();
}

function takePhoto() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const a = document.createElement("a");
    a.download = "ai-photo-zoom.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
}

function applyZoom() {
    const scale = `scale(${zoomLevel})`;
    video.style.transform = `translate(-50%, -50%) ${scale}`;
    canvas.style.transform = `translate(-50%, -50%) ${scale}`;
    zoomValueDisplay.innerText = zoomLevel.toFixed(1) + 'x';
    zoomSlider.value = zoomLevel;
}

function zoomIn() {
    zoomLevel = Math.min(zoomLevel + ZOOM_STEP, MAX_ZOOM);
    applyZoom();
    updateStatus();
}

function zoomOut() {
    zoomLevel = Math.max(zoomLevel - ZOOM_STEP, MIN_ZOOM);
    applyZoom();
    updateStatus();
}

function updateZoom(value) {
    zoomLevel = parseFloat(value);
    applyZoom();
    updateStatus();
}

function updateStatus(predictions = []) {
    const personCount = predictions.filter(p => p.class === "person" && p.score > 0.5).length;
    status.innerText = `ğŸ” PhÃ¡t hiá»‡n ${predictions.length} váº­t thá»ƒ (person: ${personCount}) | Zoom: ${zoomLevel.toFixed(1)}x`;
}

async function loadAI() {
    status.innerText = "ğŸ¤– Äang táº£i mÃ´ hÃ¬nh AI (lite cho mÆ°á»£t)...";
    try {
        model = await cocoSsd.load({ base: 'lite_mobilenet_v2' });
        status.innerText = "âœ… AI sáºµn sÃ ng";
        detect();
    } catch (err) {
        status.innerText = "âŒ Lá»—i táº£i AI: " + err.message;
    }
}

async function detect() {
    if (video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrame(detect);
        return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    frameCount++;
    if (frameCount % detectInterval === 0) {
        const predictions = await model.detect(video);
        const filteredPreds = predictions.filter(p => p.score > 0.5);

        filteredPreds.forEach(p => {
            const [x, y, w, h] = p.bbox;
            const isPerson = p.class === "person";

            ctx.strokeStyle = isPerson ? "#ff3366" : "#00ff00";
            ctx.lineWidth = isPerson ? 4 : 2;
            ctx.strokeRect(x, y, w, h);

            ctx.fillStyle = isPerson ? "#ff3366" : "#00ff00";
            ctx.font = isPerson ? "18px Arial" : "14px Arial";
            ctx.fillText(
                `${p.class} (${Math.round(p.score * 100)}%)`,
                x,
                y > 25 ? y - 8 : y + 18
            );
        });

        updateStatus(filteredPreds);
    } else {
        updateStatus();
    }

    requestAnimationFrame(detect);
}

(async () => {
    await startCamera();
    await loadAI();
    applyZoom();
})();
</script>

</body>
</html>.controls {
    position: fixed;
    bottom: 15px;
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 12px;
    z-index: 10;
}

button {
    background: rgba(0,0,0,0.7);
    color: #0f0;
    border: 1px solid #0f0;
    border-radius: 30px;
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
}

#status {
    position: fixed;
    top: 10px;
    left: 10px;
    color: #0f0;
    background: rgba(0,0,0,0.6);
    padding: 8px 12px;
    border-radius: 8px;
    font-size: 14px;
    z-index: 10;
}
</style>
</head>

<body>

<div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
</div>

<div id="status">ğŸ“· Äang khá»Ÿi Ä‘á»™ng camera...</div>

<div class="controls">
    <button onclick="switchCamera()">ğŸ” Äá»•i camera</button>
    <button onclick="takePhoto()">ğŸ“¸ Chá»¥p áº£nh</button>
    <button onclick="zoomIn()">ğŸ” + Zoom</button>
    <button onclick="zoomOut()">ğŸ” - Zoom</button>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let status = document.getElementById("status");

let currentFacing = "environment"; // "user" hoáº·c "environment"
let stream = null;
let model = null;

// Zoom variables
let zoomLevel = 1;
const MIN_ZOOM = 0.5; // ThÃªm zoom out xuá»‘ng 0.5x nhÆ° áº£nh báº¡n
const MAX_ZOOM = 10; // TÄƒng max lÃªn 10x
const ZOOM_STEP = 0.5; // BÆ°á»›c zoom lá»›n hÆ¡n Ä‘á»ƒ nhanh Ä‘áº¡t 10x

// Äá»ƒ mÆ°á»£t hÆ¡n: Chá»‰ detect má»—i X frame (giáº£m táº£i)
let frameCount = 0;
const detectInterval = 3; // Detect má»—i 3 frame (tÄƒng náº¿u muá»‘n mÆ°á»£t hÆ¡n ná»¯a)

async function startCamera() {
    if (stream) {
        stream.getTracks().forEach(t => t.stop());
    }

    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: currentFacing },
            audio: false
        });
        video.srcObject = stream;
        status.innerText = "ğŸ“¹ Camera Ä‘Ã£ báº­t";
    } catch (err) {
        status.innerText = "âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera: " + err.message;
    }
}

function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    startCamera();
}

function takePhoto() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const a = document.createElement("a");
    a.download = "ai-photo-zoom.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
}

// Zoom functions
function applyZoom() {
    const scale = `scale(${zoomLevel})`;
    video.style.transform = `translate(-50%, -50%) ${scale}`;
    canvas.style.transform = `translate(-50%, -50%) ${scale}`;
}

function zoomIn() {
    zoomLevel = Math.min(zoomLevel + ZOOM_STEP, MAX_ZOOM);
    applyZoom();
    updateStatus();
}

function zoomOut() {
    zoomLevel = Math.max(zoomLevel - ZOOM_STEP, MIN_ZOOM);
    applyZoom();
    updateStatus();
}

function updateStatus(predictions = []) {
    const personCount = predictions.filter(p => p.class === "person" && p.score > 0.5).length;
    status.innerText = `ğŸ” PhÃ¡t hiá»‡n ${predictions.length} váº­t thá»ƒ (person: ${personCount}) | Zoom: ${zoomLevel.toFixed(1)}x`;
}

async function loadAI() {
    status.innerText = "ğŸ¤– Äang táº£i mÃ´ hÃ¬nh AI (lite cho mÆ°á»£t)...";
    try {
        // Model lite cho mÆ°á»£t hÆ¡n, detect nhanh
        model = await cocoSsd.load({ base: 'lite_mobilenet_v2' });
        // Náº¿u muá»‘n xá»‹n hÆ¡n (chÃ­nh xÃ¡c cao nhÆ°ng cháº­m): model = await cocoSsd.load({ base: 'mobilenet_v2' });
        status.innerText = "âœ… AI sáºµn sÃ ng - PhÃ¡t hiá»‡n nÃ¢ng cao";
        detect();
    } catch (err) {
        status.innerText = "âŒ Lá»—i táº£i AI: " + err.message;
    }
}

async function detect() {
    if (video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrame(detect);
        return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // Váº½ video trÆ°á»›c Ä‘á»ƒ mÆ°á»£t (luÃ´n cáº­p nháº­t frame)
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    frameCount++;
    if (frameCount % detectInterval === 0) {
        const predictions = await model.detect(video);

        // Lá»c predictions tá»‘t hÆ¡n: Chá»‰ hiá»ƒn thá»‹ score > 0.5 Ä‘á»ƒ "xá»‹n" hÆ¡n, giáº£m noise
        const filteredPreds = predictions.filter(p => p.score > 0.5);

        filteredPreds.forEach(p => {
            const [x, y, w, h] = p.bbox;
            const isPerson = p.class === "person";

            ctx.strokeStyle = isPerson ? "#ff3366" : "#00ff00"; // Äá» cho person
            ctx.lineWidth = isPerson ? 4 : 2;
            ctx.strokeRect(x, y, w, h);

            ctx.fillStyle = isPerson ? "#ff3366" : "#00ff00";
            ctx.font = isPerson ? "18px Arial" : "14px Arial";
            ctx.fillText(
                `${p.class} (${Math.round(p.score * 100)}%)`,
                x,
                y > 25 ? y - 8 : y + 18
            );
        });

        updateStatus(filteredPreds);
    } else {
        // Giá»¯ status cÅ© náº¿u khÃ´ng detect má»›i
        updateStatus();
    }

    requestAnimationFrame(detect);
}

(async () => {
    await startCamera();
    await loadAI();
    applyZoom(); // Ãp dá»¥ng zoom ban Ä‘áº§u = 1x
})();
</script>

</body>
</html>.controls {
    position: fixed;
    bottom: 15px;
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 12px;
    z-index: 10;
}

button {
    background: rgba(0,0,0,0.7);
    color: #0f0;
    border: 1px solid #0f0;
    border-radius: 30px;
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
}

#status {
    position: fixed;
    top: 10px;
    left: 10px;
    color: #0f0;
    background: rgba(0,0,0,0.6);
    padding: 8px 12px;
    border-radius: 8px;
    font-size: 14px;
    z-index: 10;
}
</style>
</head>

<body>

<div id="container">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas"></canvas>
</div>

<div id="status">ğŸ“· Äang khá»Ÿi Ä‘á»™ng camera...</div>

<div class="controls">
    <button onclick="switchCamera()">ğŸ” Äá»•i camera</button>
    <button onclick="takePhoto()">ğŸ“¸ Chá»¥p áº£nh</button>
    <button onclick="zoomIn()">ğŸ” + Zoom</button>
    <button onclick="zoomOut()">ğŸ” - Zoom</button>
</div>

<script>
let video = document.getElementById("video");
let canvas = document.getElementById("canvas");
let ctx = canvas.getContext("2d");
let status = document.getElementById("status");

let currentFacing = "environment"; // "user" hoáº·c "environment"
let stream = null;
let model = null;

// Zoom variables
let zoomLevel = 1;
const MIN_ZOOM = 1;
const MAX_ZOOM = 4;
const ZOOM_STEP = 0.3;

async function startCamera() {
    if (stream) {
        stream.getTracks().forEach(t => t.stop());
    }

    try {
        stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: currentFacing },
            audio: false
        });
        video.srcObject = stream;
        status.innerText = "ğŸ“¹ Camera Ä‘Ã£ báº­t";
    } catch (err) {
        status.innerText = "âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c camera: " + err.message;
    }
}

function switchCamera() {
    currentFacing = currentFacing === "environment" ? "user" : "environment";
    startCamera();
}

function takePhoto() {
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const a = document.createElement("a");
    a.download = "ai-photo-zoom.png";
    a.href = canvas.toDataURL("image/png");
    a.click();
}

// Zoom functions
function applyZoom() {
    const scale = `scale(${zoomLevel})`;
    video.style.transform = `translate(-50%, -50%) ${scale}`;
    canvas.style.transform = `translate(-50%, -50%) ${scale}`;
}

function zoomIn() {
    zoomLevel = Math.min(zoomLevel + ZOOM_STEP, MAX_ZOOM);
    applyZoom();
    status.innerText = `ğŸ” Zoom: ${zoomLevel.toFixed(1)}x`;
}

function zoomOut() {
    zoomLevel = Math.max(zoomLevel - ZOOM_STEP, MIN_ZOOM);
    applyZoom();
    status.innerText = `ğŸ” Zoom: ${zoomLevel.toFixed(1)}x`;
}

async function loadAI() {
    status.innerText = "ğŸ¤– Äang táº£i mÃ´ hÃ¬nh AI (coco-ssd)...";
    try {
        model = await cocoSsd.load(); // CÃ³ thá»ƒ truyá»n { base: 'lite_mobilenet_v2' } náº¿u muá»‘n nháº¹ hÆ¡n
        status.innerText = "âœ… AI sáºµn sÃ ng - PhÃ¡t hiá»‡n má»i váº­t thá»ƒ";
        detect();
    } catch (err) {
        status.innerText = "âŒ Lá»—i táº£i AI: " + err.message;
    }
}

async function detect() {
    if (video.videoWidth === 0 || video.videoHeight === 0) {
        requestAnimationFrame(detect);
        return;
    }

    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    const predictions = await model.detect(video);

    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // Váº½ bounding box cho má»i váº­t thá»ƒ (Ä‘áº·c biá»‡t ná»•i báº­t "person")
    predictions.forEach(p => {
        const [x, y, w, h] = p.bbox;
        const isPerson = p.class === "person";

        ctx.strokeStyle = isPerson ? "#ff3366" : "#00ff00"; // Äá» há»“ng cho ngÆ°á»i, xanh cho váº­t khÃ¡c
        ctx.lineWidth = isPerson ? 4 : 2;
        ctx.strokeRect(x, y, w, h);

        ctx.fillStyle = isPerson ? "#ff3366" : "#00ff00";
        ctx.font = isPerson ? "18px Arial" : "14px Arial";
        ctx.fillText(
            `${p.class} (${Math.round(p.score * 100)}%)`,
            x,
            y > 25 ? y - 8 : y + 18
        );
    });

    status.innerText = `ğŸ” PhÃ¡t hiá»‡n ${predictions.length} váº­t thá»ƒ (person: ${predictions.filter(p => p.class === "person").length})`;
    
    requestAnimationFrame(detect);
}

(async () => {
    await startCamera();
    await loadAI();
    applyZoom(); // Ãp dá»¥ng zoom ban Ä‘áº§u = 1
})();
</script>

</body>
</html>
